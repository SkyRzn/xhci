diff --git a/drivers/usb/host/xhci-ring.c b/drivers/usb/host/xhci-ring.c
index 3d9d5ff..e21b0c0 100644
--- a/drivers/usb/host/xhci-ring.c
+++ b/drivers/usb/host/xhci-ring.c
@@ -2950,50 +2950,48 @@ static unsigned int count_trbs(u64 addr, u64 len)
 	return num_trbs;
 }
 
-static inline unsigned int count_trbs_needed(struct urb *urb)
+static unsigned int count_trbs_needed(struct urb *urb, int td_index)
 {
-	return count_trbs(urb->transfer_dma, urb->transfer_buffer_length);
-}
-
-static unsigned int count_sg_trbs_needed(struct urb *urb)
-{
-	struct scatterlist *sg;
-	unsigned int i, len, full_len, num_trbs = 0;
+	u32 len;
 
-	full_len = urb->transfer_buffer_length;
-
-	for_each_sg(urb->sg, sg, urb->num_mapped_sgs, i) {
-		len = sg_dma_len(sg);
-		num_trbs += count_trbs(sg_dma_address(sg), len);
-		len = min_t(unsigned int, len, full_len);
-		full_len -= len;
-		if (full_len == 0)
-			break;
+	if (usb_endpoint_xfer_isoc(&urb->ep->desc)) {
+		u64 addr;
+		addr = (u64) (urb->transfer_dma + urb->iso_frame_desc[td_index].offset);
+		len = urb->iso_frame_desc[td_index].length;
+		return count_trbs(addr, len);
 	}
 
-	return num_trbs;
-}
-
-static unsigned int count_isoc_trbs_needed(struct urb *urb, int i)
-{
-	u64 addr, len;
-
-	addr = (u64) (urb->transfer_dma + urb->iso_frame_desc[i].offset);
-	len = urb->iso_frame_desc[i].length;
+	if (urb->num_sgs) {
+		struct scatterlist *sg;
+		unsigned int i, num_trbs = 0;
+		u32 full_len = urb->transfer_buffer_length;
+
+		for_each_sg(urb->sg, sg, urb->num_mapped_sgs, i) {
+			len = sg_dma_len(sg);
+			num_trbs += count_trbs(sg_dma_address(sg), len);
+			len = min_t(u32, len, full_len); //FIXME нужна ли вообще эта проверка???
+			full_len -= len;
+			if (full_len == 0)
+				break;
+		}
 
-	return count_trbs(addr, len);
+		return num_trbs;
+	}
+	return count_trbs(urb->transfer_dma, urb->transfer_buffer_length);
 }
 
-static void check_trb_math(struct urb *urb, int running_total)
+static int check_trb_math(struct urb *urb, unsigned int running_total, unsigned int td_len)
 {
-	if (unlikely(running_total != urb->transfer_buffer_length))
+	if (unlikely(running_total != td_len)) {
 		dev_err(&urb->dev->dev, "%s - ep %#x - Miscalculated tx length, "
 				"queued %#x (%d), asked for %#x (%d)\n",
 				__func__,
 				urb->ep->desc.bEndpointAddress,
 				running_total, running_total,
-				urb->transfer_buffer_length,
-				urb->transfer_buffer_length);
+				td_len, td_len);
+		return -EINVAL;
+	}
+	return 0;
 }
 
 static void giveback_first_trb(struct xhci_hcd *xhci, int slot_id,
@@ -3105,71 +3103,213 @@ static u32 xhci_td_remainder(struct xhci_hcd *xhci, int transferred,
 	return (total_packet_count - ((transferred + trb_buff_len) / maxp));
 }
 
+/*
+ * The transfer burst count field of the isochronous TRB defines the number of
+ * bursts that are required to move all packets in this TD.  Only SuperSpeed
+ * devices can burst up to bMaxBurst number of packets per service interval.
+ * This field is zero based, meaning a value of zero in the field means one
+ * burst.  Basically, for everything but SuperSpeed devices, this field will be
+ * zero.  Only xHCI 1.0 host controllers support this field.
+ */
+static unsigned int xhci_get_burst_count(struct xhci_hcd *xhci,
+										 struct urb *urb, unsigned int total_packet_count)
+{
+	unsigned int max_burst;
+
+	if (xhci->hci_version < 0x100 || urb->dev->speed < USB_SPEED_SUPER)
+		return 0;
+
+	max_burst = urb->ep->ss_ep_comp.bMaxBurst;
+	return DIV_ROUND_UP(total_packet_count, max_burst + 1) - 1;
+}
+
+/*
+ * Returns the number of packets in the last "burst" of packets.  This field is
+ * valid for all speeds of devices.  USB 2.0 devices can only do one "burst", so
+ * the last burst packet count is equal to the total number of packets in the
+ * TD.  SuperSpeed endpoints can have up to 3 bursts.  All but the last burst
+ * must contain (bMaxBurst + 1) number of packets, but the last burst can
+ * contain 1 to (bMaxBurst + 1) packets.
+ */
+static unsigned int xhci_get_last_burst_packet_count(struct xhci_hcd *xhci,
+													 struct urb *urb, unsigned int total_packet_count)
+{
+	unsigned int max_burst;
+	unsigned int residue;
+
+	if (xhci->hci_version < 0x100)
+		return 0;
+
+	if (urb->dev->speed >= USB_SPEED_SUPER) {
+		/* bMaxBurst is zero based: 0 means 1 packet per burst */
+		max_burst = urb->ep->ss_ep_comp.bMaxBurst;
+		residue = total_packet_count % (max_burst + 1);
+		/* If residue is zero, the last burst contains (max_burst + 1)
+		 * number of packets, but the TLBPC field is zero-based.
+		 */
+		if (residue == 0)
+			return max_burst;
+		return residue - 1;
+	}
+	if (total_packet_count == 0)
+		return 0;
+	return total_packet_count - 1;
+}
+
+/*
+ * Calculates Frame ID field of the isochronous TRB identifies the
+ * target frame that the Interval associated with this Isochronous
+ * Transfer Descriptor will start on. Refer to 4.11.2.5 in 1.1 spec.
+ *
+ * Returns actual frame id on success, negative value on error.
+ */
+static int xhci_get_isoc_frame_id(struct xhci_hcd *xhci,
+								  struct urb *urb, int index)
+{
+	int start_frame, ist, ret = 0;
+	int start_frame_id, end_frame_id, current_frame_id;
+
+	if (urb->dev->speed == USB_SPEED_LOW ||
+		urb->dev->speed == USB_SPEED_FULL)
+		start_frame = urb->start_frame + index * urb->interval;
+	else
+		start_frame = (urb->start_frame + index * urb->interval) >> 3;
+
+	/* Isochronous Scheduling Threshold (IST, bits 0~3 in HCSPARAMS2):
+	 *
+	 * If bit [3] of IST is cleared to '0', software can add a TRB no
+	 * later than IST[2:0] Microframes before that TRB is scheduled to
+	 * be executed.
+	 * If bit [3] of IST is set to '1', software can add a TRB no later
+	 * than IST[2:0] Frames before that TRB is scheduled to be executed.
+	 */
+	ist = HCS_IST(xhci->hcs_params2) & 0x7;
+	if (HCS_IST(xhci->hcs_params2) & (1 << 3))
+		ist <<= 3;
+
+	/* Software shall not schedule an Isoch TD with a Frame ID value that
+	 * is less than the Start Frame ID or greater than the End Frame ID,
+	 * where:
+	 *
+	 * End Frame ID = (Current MFINDEX register value + 895 ms.) MOD 2048
+	 * Start Frame ID = (Current MFINDEX register value + IST + 1) MOD 2048
+	 *
+	 * Both the End Frame ID and Start Frame ID values are calculated
+	 * in microframes. When software determines the valid Frame ID value;
+	 * The End Frame ID value should be rounded down to the nearest Frame
+	 * boundary, and the Start Frame ID value should be rounded up to the
+	 * nearest Frame boundary.
+	 */
+	current_frame_id = readl(&xhci->run_regs->microframe_index);
+	start_frame_id = roundup(current_frame_id + ist + 1, 8);
+	end_frame_id = rounddown(current_frame_id + 895 * 8, 8);
+
+	start_frame &= 0x7ff;
+	start_frame_id = (start_frame_id >> 3) & 0x7ff;
+	end_frame_id = (end_frame_id >> 3) & 0x7ff;
+
+	xhci_dbg(xhci, "%s: index %d, reg 0x%x start_frame_id 0x%x, end_frame_id 0x%x, start_frame 0x%x\n",
+			 __func__, index, readl(&xhci->run_regs->microframe_index),
+			 start_frame_id, end_frame_id, start_frame);
+
+	if (start_frame_id < end_frame_id) {
+		if (start_frame > end_frame_id ||
+			start_frame < start_frame_id)
+			ret = -EINVAL;
+	} else if (start_frame_id > end_frame_id) {
+		if ((start_frame > end_frame_id &&
+			start_frame < start_frame_id))
+			ret = -EINVAL;
+	} else {
+		ret = -EINVAL;
+	}
+
+	if (index == 0) {
+		if (ret == -EINVAL || start_frame == start_frame_id) {
+			start_frame = start_frame_id + 1;
+			if (urb->dev->speed == USB_SPEED_LOW ||
+				urb->dev->speed == USB_SPEED_FULL)
+				urb->start_frame = start_frame;
+			else
+				urb->start_frame = start_frame << 3;
+			ret = 0;
+		}
+	}
+
+	if (ret) {
+		xhci_warn(xhci, "Frame ID %d (reg %d, index %d) beyond range (%d, %d)\n",
+				  start_frame, current_frame_id, index,
+			start_frame_id, end_frame_id);
+		xhci_warn(xhci, "Ignore frame ID field, use SIA bit instead\n");
+		return ret;
+	}
+
+	return start_frame;
+}
+
+static void xhci_isoc_trb_field_fill(struct xhci_hcd *xhci, struct urb *urb,
+									 int td_index, u32 td_len, u32 *field, u32 *length_field)
+{
+	struct xhci_virt_ep *xep;
+	u32 sia_frame_id;
+	int frame_id;
+	unsigned int total_pkt_count, max_pkt;
+	unsigned int burst_count, last_burst_pkt_count;
+
+	xep = &xhci->devs[urb->dev->slot_id]->eps[xhci_get_endpoint_index(&urb->ep->desc)];
+
+	max_pkt = GET_MAX_PACKET(usb_endpoint_maxp(&urb->ep->desc));
+	total_pkt_count = DIV_ROUND_UP(td_len, max_pkt);
+
+	/* A zero-length transfer still involves at least one packet. */
+	if (total_pkt_count == 0)
+		total_pkt_count++;
+	burst_count = xhci_get_burst_count(xhci, urb, total_pkt_count);
+	last_burst_pkt_count = xhci_get_last_burst_packet_count(xhci,
+															urb, total_pkt_count);
+
+	/* use SIA as default, if frame id is used overwrite it */
+	sia_frame_id = TRB_SIA;
+	if (!(urb->transfer_flags & URB_ISO_ASAP) &&
+		HCC_CFC(xhci->hcc_params)) {
+		frame_id = xhci_get_isoc_frame_id(xhci, urb, td_index);
+	if (frame_id >= 0)
+		sia_frame_id = TRB_FRAME_ID(frame_id);
+		}
+
+		*field = TRB_TYPE(TRB_ISOC) |
+		TRB_TLBPC(last_burst_pkt_count) |
+		sia_frame_id;
+
+	/* xhci 1.1 with ETE uses TD_Size field for TBC, old is Rsvdz */
+	if (xep->use_extended_tbc)
+		*length_field = TRB_TD_SIZE_TBC(burst_count);
+	else
+		*field |= TRB_TBC(burst_count);
+}
+
 /* This is very similar to what ehci-q.c qtd_fill() does */
-int xhci_queue_bulk_tx(struct xhci_hcd *xhci, gfp_t mem_flags,
-		struct urb *urb, int slot_id, unsigned int ep_index)
+static int queue_td(struct xhci_hcd *xhci, struct urb *urb, int td_index, u64 addr, u32 td_len, unsigned int num_trbs)
 {
 	struct xhci_ring *ep_ring;
-	struct urb_priv *urb_priv;
 	struct xhci_td *td;
-	struct xhci_generic_trb *start_trb;
+	struct urb_priv *urb_priv;
 	struct scatterlist *sg = NULL;
 	bool more_trbs_coming;
-	bool zero_length_needed;
-	unsigned int num_trbs, last_trb_num, i;
-	unsigned int start_cycle, num_sgs = 0;
+	unsigned int i, num_sgs = 0;
 	unsigned int running_total, block_len, trb_buff_len;
-	unsigned int full_len;
-	int ret;
 	u32 field, length_field, remainder;
-	u64 addr;
 
+	urb_priv = urb->hcpriv;
+	td = urb_priv->td[td_index];
 	ep_ring = xhci_urb_to_transfer_ring(xhci, urb);
-	if (!ep_ring)
-		return -EINVAL;
 
 	/* If we have scatter/gather list, we use it. */
 	if (urb->num_sgs) {
-		num_sgs = urb->num_mapped_sgs;
 		sg = urb->sg;
-		num_trbs = count_sg_trbs_needed(urb);
-	} else
-		num_trbs = count_trbs_needed(urb);
-
-	ret = prepare_transfer(xhci, xhci->devs[slot_id],
-			ep_index, urb->stream_id,
-			num_trbs, urb, 0, mem_flags);
-	if (unlikely(ret < 0))
-		return ret;
-
-	urb_priv = urb->hcpriv;
-
-	last_trb_num = num_trbs - 1;
-
-	/* Deal with URB_ZERO_PACKET - need one more td/trb */
-	zero_length_needed = urb->transfer_flags & URB_ZERO_PACKET &&
-		urb_priv->length == 2;
-	if (zero_length_needed) {
-		num_trbs++;
-		xhci_dbg(xhci, "Creating zero length td.\n");
-		ret = prepare_transfer(xhci, xhci->devs[slot_id],
-				ep_index, urb->stream_id,
-				1, urb, 1, mem_flags);
-		if (unlikely(ret < 0))
-			return ret;
+		num_sgs = urb->num_mapped_sgs;
 	}
 
-	td = urb_priv->td[0];
-
-	/*
-	 * Don't give the first TRB to the hardware (by toggling the cycle bit)
-	 * until we've finished creating all the other TRBs.  The ring's cycle
-	 * state may change as we enqueue the other TRBs, so save it too.
-	 */
-	start_trb = &ep_ring->enqueue->generic;
-	start_cycle = ep_ring->cycle_state;
-
-	full_len = urb->transfer_buffer_length;
 	running_total = 0;
 	block_len = 0;
 
@@ -3182,15 +3322,12 @@ int xhci_queue_bulk_tx(struct xhci_hcd *xhci, gfp_t mem_flags,
 			if (sg) {
 				addr = (u64) sg_dma_address(sg);
 				block_len = sg_dma_len(sg);
-			} else {
-				addr = (u64) urb->transfer_dma;
-				block_len = full_len;
-			}
+			} else
+				block_len = td_len;
+
 			/* TRB buffer should not cross 64KB boundaries */
 			trb_buff_len = TRB_BUFF_LEN_UP_TO_BOUNDARY(addr);
-			trb_buff_len = min_t(unsigned int,
-								trb_buff_len,
-								block_len);
+			trb_buff_len = min_t(unsigned int, trb_buff_len, block_len);
 		} else {
 			/* Further through the contiguous block. */
 			trb_buff_len = block_len;
@@ -3198,48 +3335,53 @@ int xhci_queue_bulk_tx(struct xhci_hcd *xhci, gfp_t mem_flags,
 				trb_buff_len = TRB_MAX_BUFF_SIZE;
 		}
 
-		if (running_total + trb_buff_len > full_len)
-			trb_buff_len = full_len - running_total;
+		if (running_total + trb_buff_len > td_len)
+			trb_buff_len = td_len - running_total;
+
+		/* Set the TRB length, TD size, and interrupter fields. */
+		remainder = xhci_td_remainder(xhci, running_total,
+									  trb_buff_len, td_len,
+								urb, num_trbs - i - 1);
+
+		field = TRB_TYPE(TRB_NORMAL);
+		length_field = TRB_TD_SIZE(remainder);
+
+		if (i == 0 && usb_endpoint_xfer_isoc(&urb->ep->desc))
+			xhci_isoc_trb_field_fill(xhci, urb, td_index, td_len, &field, &length_field); //FIXME заменил ep на urb->ep
+
+		length_field |= TRB_LEN(trb_buff_len) | TRB_INTR_TARGET(0);
 
 		/* Don't change the cycle bit of the first TRB until later */
-		if (i == 0) {
-			if (start_cycle == 0)
+		if (i == 0 && td_index == 0) {
+			if (ep_ring->cycle_state == 0)
 				field |= TRB_CYCLE;
 		} else
 			field |= ep_ring->cycle_state;
 
+		/* Only set interrupt on short packet for IN endpoints */
+		if (usb_urb_dir_in(urb))
+			field |= TRB_ISP;
+
 		/* Chain all the TRBs together; clear the chain bit in the last
 		 * TRB to indicate it's the last TRB in the chain.
 		 */
-		if (i < last_trb_num) {
+		if (i < num_trbs - 1) {
+			more_trbs_coming = true;
 			field |= TRB_CHAIN;
 		} else {
+			more_trbs_coming = false;
 			field |= TRB_IOC;
-			if (i == last_trb_num)
-				td->last_trb = ep_ring->enqueue;
-			else if (zero_length_needed) {
-				trb_buff_len = 0;
-				urb_priv->td[1]->last_trb = ep_ring->enqueue;
+			td->last_trb = ep_ring->enqueue;
+
+			if (usb_endpoint_xfer_isoc(&urb->ep->desc)) {
+				/* set BEI, except for the last TD */
+				if (xhci->hci_version >= 0x100 &&
+					!(xhci->quirks & XHCI_AVOID_BEI) &&
+					td_index < urb->number_of_packets - 1)
+					field |= TRB_BEI;
 			}
 		}
 
-		/* Only set interrupt on short packet for IN endpoints */
-		if (usb_urb_dir_in(urb))
-			field |= TRB_ISP;
-
-		/* Set the TRB length, TD size, and interrupter fields. */
-		remainder = xhci_td_remainder(xhci, running_total,
-							trb_buff_len, full_len,
-							urb, num_trbs - i - 1);
-
-		length_field = TRB_LEN(trb_buff_len) |
-			TRB_TD_SIZE(remainder) |
-			TRB_INTR_TARGET(0);
-
-		if (i < num_trbs - 1)
-			more_trbs_coming = true;
-		else
-			more_trbs_coming = false;
 		queue_trb(xhci, ep_ring, more_trbs_coming,
 				lower_32_bits(addr),
 				upper_32_bits(addr),
@@ -3261,10 +3403,64 @@ int xhci_queue_bulk_tx(struct xhci_hcd *xhci, gfp_t mem_flags,
 		}
 	}
 
-	check_trb_math(urb, running_total);
+	return check_trb_math(urb, running_total, td_len);
+}
+
+/* This is very similar to what ehci-q.c qtd_fill() does */
+int xhci_queue_bulk_tx(struct xhci_hcd *xhci, gfp_t mem_flags,
+					   struct urb *urb, int slot_id, unsigned int ep_index)
+{
+	struct xhci_ring *ep_ring;
+	struct urb_priv *urb_priv;
+	struct xhci_generic_trb *start_trb;
+	bool zero_length_needed;
+	unsigned int start_cycle, num_trbs;
+	int ret;
+
+	ep_ring = xhci_urb_to_transfer_ring(xhci, urb);
+	if (!ep_ring)
+		return -EINVAL;
+
+	/* If we have scatter/gather list, we use it. */
+	num_trbs = count_trbs_needed(urb, 0);
+
+	ret = prepare_transfer(xhci, xhci->devs[slot_id],
+						   ep_index, urb->stream_id,
+						num_trbs, urb, 0, mem_flags);
+	if (unlikely(ret < 0))
+		return ret;
+
+	urb_priv = urb->hcpriv;
+
+	/* Deal with URB_ZERO_PACKET - need one more td/trb */
+	zero_length_needed = urb->transfer_flags & URB_ZERO_PACKET &&
+						urb_priv->length == 2;
+	if (zero_length_needed) {
+		xhci_dbg(xhci, "Creating zero length td.\n");
+		ret = prepare_transfer(xhci, xhci->devs[slot_id],
+								ep_index, urb->stream_id,
+								1, urb, 1, mem_flags);
+		if (unlikely(ret < 0))
+			return ret;
+	}
+
+	/*
+	 * Don't give the first TRB to the hardware (by toggling the cycle bit)
+	 * until we've finished creating all the other TRBs.  The ring's cycle
+	 * state may change as we enqueue the other TRBs, so save it too.
+	 */
+	start_trb = &ep_ring->enqueue->generic;
+	start_cycle = ep_ring->cycle_state;
+
+	queue_td(xhci, urb, 0, urb->transfer_dma, urb->transfer_buffer_length, num_trbs);
+
+	if (zero_length_needed) {
+		queue_td(xhci, urb, 1, urb->transfer_dma, 0, num_trbs);
+	}
 	giveback_first_trb(xhci, slot_id, ep_index, urb->stream_id,
-			start_cycle, start_trb);
-	return 0;
+					   start_cycle, start_trb);
+
+	return ret;
 }
 
 /* Caller must have locked xhci->lock */
@@ -3390,168 +3586,18 @@ int xhci_queue_ctrl_tx(struct xhci_hcd *xhci, gfp_t mem_flags,
 	return 0;
 }
 
-/*
- * The transfer burst count field of the isochronous TRB defines the number of
- * bursts that are required to move all packets in this TD.  Only SuperSpeed
- * devices can burst up to bMaxBurst number of packets per service interval.
- * This field is zero based, meaning a value of zero in the field means one
- * burst.  Basically, for everything but SuperSpeed devices, this field will be
- * zero.  Only xHCI 1.0 host controllers support this field.
- */
-static unsigned int xhci_get_burst_count(struct xhci_hcd *xhci,
-		struct urb *urb, unsigned int total_packet_count)
-{
-	unsigned int max_burst;
-
-	if (xhci->hci_version < 0x100 || urb->dev->speed < USB_SPEED_SUPER)
-		return 0;
-
-	max_burst = urb->ep->ss_ep_comp.bMaxBurst;
-	return DIV_ROUND_UP(total_packet_count, max_burst + 1) - 1;
-}
-
-/*
- * Returns the number of packets in the last "burst" of packets.  This field is
- * valid for all speeds of devices.  USB 2.0 devices can only do one "burst", so
- * the last burst packet count is equal to the total number of packets in the
- * TD.  SuperSpeed endpoints can have up to 3 bursts.  All but the last burst
- * must contain (bMaxBurst + 1) number of packets, but the last burst can
- * contain 1 to (bMaxBurst + 1) packets.
- */
-static unsigned int xhci_get_last_burst_packet_count(struct xhci_hcd *xhci,
-		struct urb *urb, unsigned int total_packet_count)
-{
-	unsigned int max_burst;
-	unsigned int residue;
-
-	if (xhci->hci_version < 0x100)
-		return 0;
-
-	if (urb->dev->speed >= USB_SPEED_SUPER) {
-		/* bMaxBurst is zero based: 0 means 1 packet per burst */
-		max_burst = urb->ep->ss_ep_comp.bMaxBurst;
-		residue = total_packet_count % (max_burst + 1);
-		/* If residue is zero, the last burst contains (max_burst + 1)
-		 * number of packets, but the TLBPC field is zero-based.
-		 */
-		if (residue == 0)
-			return max_burst;
-		return residue - 1;
-	}
-	if (total_packet_count == 0)
-		return 0;
-	return total_packet_count - 1;
-}
-
-/*
- * Calculates Frame ID field of the isochronous TRB identifies the
- * target frame that the Interval associated with this Isochronous
- * Transfer Descriptor will start on. Refer to 4.11.2.5 in 1.1 spec.
- *
- * Returns actual frame id on success, negative value on error.
- */
-static int xhci_get_isoc_frame_id(struct xhci_hcd *xhci,
-		struct urb *urb, int index)
-{
-	int start_frame, ist, ret = 0;
-	int start_frame_id, end_frame_id, current_frame_id;
-
-	if (urb->dev->speed == USB_SPEED_LOW ||
-			urb->dev->speed == USB_SPEED_FULL)
-		start_frame = urb->start_frame + index * urb->interval;
-	else
-		start_frame = (urb->start_frame + index * urb->interval) >> 3;
-
-	/* Isochronous Scheduling Threshold (IST, bits 0~3 in HCSPARAMS2):
-	 *
-	 * If bit [3] of IST is cleared to '0', software can add a TRB no
-	 * later than IST[2:0] Microframes before that TRB is scheduled to
-	 * be executed.
-	 * If bit [3] of IST is set to '1', software can add a TRB no later
-	 * than IST[2:0] Frames before that TRB is scheduled to be executed.
-	 */
-	ist = HCS_IST(xhci->hcs_params2) & 0x7;
-	if (HCS_IST(xhci->hcs_params2) & (1 << 3))
-		ist <<= 3;
-
-	/* Software shall not schedule an Isoch TD with a Frame ID value that
-	 * is less than the Start Frame ID or greater than the End Frame ID,
-	 * where:
-	 *
-	 * End Frame ID = (Current MFINDEX register value + 895 ms.) MOD 2048
-	 * Start Frame ID = (Current MFINDEX register value + IST + 1) MOD 2048
-	 *
-	 * Both the End Frame ID and Start Frame ID values are calculated
-	 * in microframes. When software determines the valid Frame ID value;
-	 * The End Frame ID value should be rounded down to the nearest Frame
-	 * boundary, and the Start Frame ID value should be rounded up to the
-	 * nearest Frame boundary.
-	 */
-	current_frame_id = readl(&xhci->run_regs->microframe_index);
-	start_frame_id = roundup(current_frame_id + ist + 1, 8);
-	end_frame_id = rounddown(current_frame_id + 895 * 8, 8);
-
-	start_frame &= 0x7ff;
-	start_frame_id = (start_frame_id >> 3) & 0x7ff;
-	end_frame_id = (end_frame_id >> 3) & 0x7ff;
-
-	xhci_dbg(xhci, "%s: index %d, reg 0x%x start_frame_id 0x%x, end_frame_id 0x%x, start_frame 0x%x\n",
-		 __func__, index, readl(&xhci->run_regs->microframe_index),
-		 start_frame_id, end_frame_id, start_frame);
-
-	if (start_frame_id < end_frame_id) {
-		if (start_frame > end_frame_id ||
-				start_frame < start_frame_id)
-			ret = -EINVAL;
-	} else if (start_frame_id > end_frame_id) {
-		if ((start_frame > end_frame_id &&
-				start_frame < start_frame_id))
-			ret = -EINVAL;
-	} else {
-			ret = -EINVAL;
-	}
-
-	if (index == 0) {
-		if (ret == -EINVAL || start_frame == start_frame_id) {
-			start_frame = start_frame_id + 1;
-			if (urb->dev->speed == USB_SPEED_LOW ||
-					urb->dev->speed == USB_SPEED_FULL)
-				urb->start_frame = start_frame;
-			else
-				urb->start_frame = start_frame << 3;
-			ret = 0;
-		}
-	}
-
-	if (ret) {
-		xhci_warn(xhci, "Frame ID %d (reg %d, index %d) beyond range (%d, %d)\n",
-				start_frame, current_frame_id, index,
-				start_frame_id, end_frame_id);
-		xhci_warn(xhci, "Ignore frame ID field, use SIA bit instead\n");
-		return ret;
-	}
-
-	return start_frame;
-}
-
 /* This is for isoc transfer */
 static int xhci_queue_isoc_tx(struct xhci_hcd *xhci, gfp_t mem_flags,
 		struct urb *urb, int slot_id, unsigned int ep_index)
 {
 	struct xhci_ring *ep_ring;
 	struct urb_priv *urb_priv;
-	struct xhci_td *td;
 	int num_tds, trbs_per_td;
 	struct xhci_generic_trb *start_trb;
-	bool first_trb;
 	int start_cycle;
-	u32 field, length_field;
-	int running_total, trb_buff_len, td_len, td_remain_len, ret;
+	int i, td_len, ret;
 	u64 start_addr, addr;
-	int i, j;
-	bool more_trbs_coming;
 	struct xhci_virt_ep *xep;
-	int frame_id;
 
 	xep = &xhci->devs[slot_id]->eps[ep_index];
 	ep_ring = xhci->devs[slot_id]->eps[ep_index].ring;
@@ -3568,26 +3614,10 @@ static int xhci_queue_isoc_tx(struct xhci_hcd *xhci, gfp_t mem_flags,
 	urb_priv = urb->hcpriv;
 	/* Queue the TRBs for each TD, even if they are zero-length */
 	for (i = 0; i < num_tds; i++) {
-		unsigned int total_pkt_count, max_pkt;
-		unsigned int burst_count, last_burst_pkt_count;
-		u32 sia_frame_id;
-
-		first_trb = true;
-		running_total = 0;
 		addr = start_addr + urb->iso_frame_desc[i].offset;
 		td_len = urb->iso_frame_desc[i].length;
-		td_remain_len = td_len;
-		max_pkt = GET_MAX_PACKET(usb_endpoint_maxp(&urb->ep->desc));
-		total_pkt_count = DIV_ROUND_UP(td_len, max_pkt);
 
-		/* A zero-length transfer still involves at least one packet. */
-		if (total_pkt_count == 0)
-			total_pkt_count++;
-		burst_count = xhci_get_burst_count(xhci, urb, total_pkt_count);
-		last_burst_pkt_count = xhci_get_last_burst_packet_count(xhci,
-							urb, total_pkt_count);
-
-		trbs_per_td = count_isoc_trbs_needed(urb, i);
+		trbs_per_td = count_trbs_needed(urb, i);
 
 		ret = prepare_transfer(xhci, xhci->devs[slot_id], ep_index,
 				urb->stream_id, trbs_per_td, urb, i, mem_flags);
@@ -3596,94 +3626,10 @@ static int xhci_queue_isoc_tx(struct xhci_hcd *xhci, gfp_t mem_flags,
 				return ret;
 			goto cleanup;
 		}
-		td = urb_priv->td[i];
-
-		/* use SIA as default, if frame id is used overwrite it */
-		sia_frame_id = TRB_SIA;
-		if (!(urb->transfer_flags & URB_ISO_ASAP) &&
-		    HCC_CFC(xhci->hcc_params)) {
-			frame_id = xhci_get_isoc_frame_id(xhci, urb, i);
-			if (frame_id >= 0)
-				sia_frame_id = TRB_FRAME_ID(frame_id);
-		}
-		/*
-		 * Set isoc specific data for the first TRB in a TD.
-		 * Prevent HW from getting the TRBs by keeping the cycle state
-		 * inverted in the first TDs isoc TRB.
-		 */
-		field = TRB_TYPE(TRB_ISOC) |
-			TRB_TLBPC(last_burst_pkt_count) |
-			sia_frame_id |
-			(i ? ep_ring->cycle_state : !start_cycle);
-
-		/* xhci 1.1 with ETE uses TD_Size field for TBC, old is Rsvdz */
-		if (!xep->use_extended_tbc)
-			field |= TRB_TBC(burst_count);
-
-		/* fill the rest of the TRB fields, and remaining normal TRBs */
-		for (j = 0; j < trbs_per_td; j++) {
-			u32 remainder = 0;
-
-			/* only first TRB is isoc, overwrite otherwise */
-			if (!first_trb)
-				field = TRB_TYPE(TRB_NORMAL) |
-					ep_ring->cycle_state;
-
-			/* Only set interrupt on short packet for IN EPs */
-			if (usb_urb_dir_in(urb))
-				field |= TRB_ISP;
-
-			/* Set the chain bit for all except the last TRB  */
-			if (j < trbs_per_td - 1) {
-				more_trbs_coming = true;
-				field |= TRB_CHAIN;
-			} else {
-				more_trbs_coming = false;
-				td->last_trb = ep_ring->enqueue;
-				field |= TRB_IOC;
-				/* set BEI, except for the last TD */
-				if (xhci->hci_version >= 0x100 &&
-				    !(xhci->quirks & XHCI_AVOID_BEI) &&
-				    i < num_tds - 1)
-					field |= TRB_BEI;
-			}
-			/* Calculate TRB length */
-			trb_buff_len = TRB_BUFF_LEN_UP_TO_BOUNDARY(addr);
-			if (trb_buff_len > td_remain_len)
-				trb_buff_len = td_remain_len;
 
-			/* Set the TRB length, TD size, & interrupter fields. */
-			remainder = xhci_td_remainder(xhci, running_total,
-						   trb_buff_len, td_len,
-						   urb, trbs_per_td - j - 1);
-
-			length_field = TRB_LEN(trb_buff_len) |
-				TRB_INTR_TARGET(0);
-
-			/* xhci 1.1 with ETE uses TD Size field for TBC */
-			if (first_trb && xep->use_extended_tbc)
-				length_field |= TRB_TD_SIZE_TBC(burst_count);
-			else
-				length_field |= TRB_TD_SIZE(remainder);
-			first_trb = false;
-
-			queue_trb(xhci, ep_ring, more_trbs_coming,
-				lower_32_bits(addr),
-				upper_32_bits(addr),
-				length_field,
-				field);
-			running_total += trb_buff_len;
-
-			addr += trb_buff_len;
-			td_remain_len -= trb_buff_len;
-		}
-
-		/* Check TD length */
-		if (running_total != td_len) {
-			xhci_err(xhci, "ISOC TD length unmatch\n");
-			ret = -EINVAL;
+		ret = queue_td(xhci, urb, i, addr, td_len, trbs_per_td);
+		if (ret)
 			goto cleanup;
-		}
 	}
 
 	/* store the next frame id */
@@ -3750,7 +3696,7 @@ int xhci_queue_isoc_tx_prepare(struct xhci_hcd *xhci, gfp_t mem_flags,
 	num_trbs = 0;
 	num_tds = urb->number_of_packets;
 	for (i = 0; i < num_tds; i++)
-		num_trbs += count_isoc_trbs_needed(urb, i);
+		num_trbs += count_trbs_needed(urb, i);
 
 	/* Check the ring to guarantee there is enough room for the whole urb.
 	 * Do not insert any td of the urb to the ring if the check failed.
